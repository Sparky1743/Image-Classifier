{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b904e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\birud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122a7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_df = pd.read_csv(r\"C:\\Users\\birud\\OneDrive - iitgn.ac.in\\github\\Image Classifier\\Step3 - Model Creation\\Xtrain and Ytrain\\Xtrain.csv\")\n",
    "Ytrain_df = pd.read_csv(r\"C:\\Users\\birud\\OneDrive - iitgn.ac.in\\github\\Image Classifier\\Step3 - Model Creation\\Xtrain and Ytrain\\Ytrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0016e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(622, 67500)\n",
      "(622, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_df.shape)\n",
    "print(Ytrain_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f17c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dimensions = (150, 150)\n",
    "# folder_name = 'Test_preprocessed'\n",
    "\n",
    "def preprocessing(i):\n",
    "        path = r'C:\\Users\\birud\\OneDrive - iitgn.ac.in\\github\\Image Classifier\\Step3 - Model Creation\\Test_Images\\%s.jpg' %(i)\n",
    "        image = cv2.imread(path)\n",
    "        # Convert to RGB model\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = cv2.resize(rgb_image, new_dimensions)\n",
    "\n",
    "        # Normalize pixel values to the range (0, 1)\n",
    "        normalized_image = resized_image / 255.0\n",
    "        pixels = np.array(normalized_image)\n",
    "        flattened_pixels = pixels.reshape(-1)\n",
    "        \n",
    "        return flattened_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3c5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(Xtrain_df,Ytrain_df, test_size = 0.2, random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df3ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\birud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(67500,)), \n",
    "        Dense(units = 255, activation = \"relu\"),\n",
    "        Dense(units = 150, activation = \"relu\"),\n",
    "        Dense(units = 5, activation = \"linear\"),\n",
    "    ], name = \"image_classifier\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79ce0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"image_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 255)               17212755  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               38400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 755       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17251910 (65.81 MB)\n",
      "Trainable params: 17251910 (65.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a67c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape = (67500, 255), b1 shape = (255,)\n",
      "W2 shape = (255, 150), b2 shape = (150,)\n",
      "W3 shape = (150, 5), b3 shape = (5,)\n"
     ]
    }
   ],
   "source": [
    "[layer1, layer2, layer3] = model.layers\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6facb13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\birud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\birud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "16/16 [==============================] - 2s 93ms/step - loss: 37.4987 - accuracy: 0.2656 - val_loss: 52.9841 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 11.0948 - accuracy: 0.3400 - val_loss: 48.6889 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 5.2636 - accuracy: 0.4346 - val_loss: 12.5616 - val_accuracy: 0.0320\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 4.3493 - accuracy: 0.4366 - val_loss: 19.8285 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.6533 - accuracy: 0.5332 - val_loss: 18.0446 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.4965 - accuracy: 0.5392 - val_loss: 9.6653 - val_accuracy: 0.0480\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.9862 - accuracy: 0.5091 - val_loss: 18.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 1.7100 - accuracy: 0.6097 - val_loss: 12.6806 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 1.3053 - accuracy: 0.6660 - val_loss: 11.4752 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.7995 - accuracy: 0.7445 - val_loss: 4.9430 - val_accuracy: 0.0400\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.3758 - accuracy: 0.8571 - val_loss: 7.1281 - val_accuracy: 0.0320\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.3902 - accuracy: 0.8692 - val_loss: 17.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.6639 - accuracy: 0.7606 - val_loss: 25.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 1.3826 - accuracy: 0.6881 - val_loss: 25.9356 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 2.5654 - accuracy: 0.5775 - val_loss: 9.4142 - val_accuracy: 0.0240\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.9224 - accuracy: 0.7545 - val_loss: 10.4893 - val_accuracy: 0.0080\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.4315 - accuracy: 0.8410 - val_loss: 11.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.3420 - accuracy: 0.8753 - val_loss: 13.8843 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.2899 - accuracy: 0.8913 - val_loss: 7.6959 - val_accuracy: 0.0160\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.2964 - accuracy: 0.8732 - val_loss: 19.2653 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    Xtrain_df,Ytrain_df,\n",
    "    epochs=20, batch_size = 32, validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e79486b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 4.1976 - accuracy: 0.7680\n",
      "0.7680000066757202\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b058bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83137255 0.83137255 0.86666667 ... 0.59215686 0.73333333 0.54509804]\n"
     ]
    }
   ],
   "source": [
    "# Load the test image\n",
    "test_image = preprocessing(5)\n",
    "print(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d532c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      " predicting a Two: \n",
      "[[  9.825708    7.2254214   3.129969    1.9386996 -14.41153  ]]\n",
      " Largest Prediction index: 0\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_image.reshape(1,67500))  # prediction\n",
    "\n",
    "print(f\" predicting a Two: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7582deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicting a Two. Probability vector: \n",
      "[[9.2948544e-01 6.9016397e-02 1.1489993e-03 3.4910679e-04 2.7678589e-11]]\n",
      "Total of predictions: 1.000\n"
     ]
    }
   ],
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_p}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_p):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8cbb377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.argmax(prediction_p): 0\n"
     ]
    }
   ],
   "source": [
    "yhat = np.argmax(prediction_p)\n",
    "\n",
    "print(f\"np.argmax(prediction_p): {yhat}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
