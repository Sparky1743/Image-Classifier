{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9734e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e0bfb",
   "metadata": {},
   "source": [
    "## Below is the code for Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c0be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process image7, going to next one\n",
      "Failed to process image23, going to next one\n",
      "Failed to process image26, going to next one\n",
      "Failed to process image33, going to next one\n",
      "Failed to process image60, going to next one\n",
      "Failed to process image62, going to next one\n",
      "Failed to process image71, going to next one\n",
      "Failed to process image101, going to next one\n",
      "Failed to process image111, going to next one\n",
      "done\n",
      "Filtered 131 / 140 images\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'Filtered_maltese_images' \n",
    "new_dimensions = (150, 150)\n",
    "dataset_size = 140\n",
    "missed_count = 0\n",
    "\n",
    "if not os.path.isdir(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(dataset_size):\n",
    "    try:\n",
    "        path = r\"C:\\Users\\birud\\OneDrive - iitgn.ac.in\\github\\Image Classifier\\WoC_6.0_Checkpoint_2\\dog_maltese_images\\%s.jpg\" % (i)\n",
    "        image = cv2.imread(path)\n",
    "\n",
    "        # Convert all images to RGB model\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = cv2.resize(rgb_image, new_dimensions)\n",
    "\n",
    "        # Normalize pixel values to the range (0, 1)\n",
    "        normalized_image = resized_image / 255.0\n",
    "\n",
    "        # Saving filtered images\n",
    "        save_path = os.path.join(folder_name, f\"{i}_resized_rgb_normalized.jpg\")\n",
    "        cv2.imwrite(save_path, (normalized_image * 255).astype('uint8'))\n",
    "        \n",
    "    except:\n",
    "        print(f\"Failed to process image{i}, going to next one\")\n",
    "        missed_count += 1\n",
    "        continue\n",
    "\n",
    "total_filtered = dataset_size - missed_count\n",
    "print('done')\n",
    "print(f'Filtered {total_filtered} / {dataset_size} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f1368",
   "metadata": {},
   "source": [
    "## Below code is used to convert the images to1d arrays and store them in Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aea657d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = []\n",
    "ytrain = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0df4740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the pixel values as a 1d array in Xtrain\n",
    "count = 0\n",
    "for i in range(140):\n",
    "    try:\n",
    "        path_resized = r\"C:\\Users\\birud\\OneDrive - iitgn.ac.in\\github\\Image Classifier\\Step2 - Image Filtering\\Filtered_maltese_images\\%s_resized_rgb_normalized.jpg\" % (i)\n",
    "        pixels = np.array(cv2.imread(path_resized))\n",
    "        flattened_pixels = pixels.reshape(-1)\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    if flattened_pixels[0] != None:\n",
    "        XTrain.append(flattened_pixels)\n",
    "        count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c50a37ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "print(len(XTrain))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52fdc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = black_russian_terrier\n",
    "# 1 = bulldog\n",
    "# 2 = dalmatian\n",
    "# 3 = german_shepherd\n",
    "# 4 = maltese\n",
    "\n",
    "choose_label = 4\n",
    "for i in range(count):\n",
    "    ytrain.append(choose_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa6286c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n",
      "631\n"
     ]
    }
   ],
   "source": [
    "print(len(ytrain))\n",
    "print(len(XTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ea36497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
      "0         87      101       60      111      127       80      113      132   \n",
      "1        106       85       40      105       86       35      116       98   \n",
      "2        141      140       84      146      145       87      156      156   \n",
      "3        255      255      255      255      255      255      255      255   \n",
      "4        203      206      211      198      201      206      198      201   \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "626      203      221      232      204      222      233      205      223   \n",
      "627      171      171      157      167      167      155      153      154   \n",
      "628       37       27        9       38       28       10       44       31   \n",
      "629       28       85       46       19       78       40       13       71   \n",
      "630       37       36        0       41       38        0       41       35   \n",
      "\n",
      "     pixel_8  pixel_9  ...  pixel_67490  pixel_67491  pixel_67492  \\\n",
      "0         77       88  ...          112          151          177   \n",
      "1         35      120  ...           92          189          142   \n",
      "2         96      176  ...           76          182          215   \n",
      "3        255      255  ...          255          255          255   \n",
      "4        206      200  ...          251          242          247   \n",
      "..       ...      ...  ...          ...          ...          ...   \n",
      "626      234      208  ...          255          249          254   \n",
      "627      145      170  ...          253          254          255   \n",
      "628       17       47  ...          113          118          115   \n",
      "629       36       11  ...           11           14           70   \n",
      "630        0       43  ...           80          143          136   \n",
      "\n",
      "     pixel_67493  pixel_67494  pixel_67495  pixel_67496  pixel_67497  \\\n",
      "0            101          147          173           90          152   \n",
      "1            104          180          133           95          188   \n",
      "2            118          211          243          148          133   \n",
      "3            255          255          255          255          255   \n",
      "4            250          242          247          250          240   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "626          255          243          249          254          235   \n",
      "627          253          254          255          253          254   \n",
      "628          110          125          122          117          117   \n",
      "629           21           19           72           28           17   \n",
      "630           93          127          121           80          120   \n",
      "\n",
      "     pixel_67498  pixel_67499  \n",
      "0            178           94  \n",
      "1            141          103  \n",
      "2            165           70  \n",
      "3            255          255  \n",
      "4            245          248  \n",
      "..           ...          ...  \n",
      "626          244          248  \n",
      "627          255          253  \n",
      "628          114          109  \n",
      "629           67           25  \n",
      "630          113           74  \n",
      "\n",
      "[631 rows x 67500 columns]\n",
      "---------------------------------------------------\n",
      "     Labels\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "..      ...\n",
      "626       4\n",
      "627       4\n",
      "628       4\n",
      "629       4\n",
      "630       4\n",
      "\n",
      "[631 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "column_names = [f\"pixel_{i}\" for i in range(67500)]\n",
    "XTrain_df = pd.DataFrame(XTrain, columns=column_names)\n",
    "ytrain = np.array(ytrain)\n",
    "ytrain_df = pd.DataFrame({'Labels': ytrain})\n",
    "# Display the DataFrame\n",
    "print(XTrain_df)\n",
    "print(\"---------------------------------------------------\")\n",
    "print(ytrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e0addac",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"C:\\Users\\birud\\OneDrive - iitgn.ac.in\\github\\Image Classifier\\Step3 - Model Creation\\Xtrain and Ytrain\"\n",
    "Xtrain_file = os.path.join(save_path, 'Xtrain.csv')\n",
    "Ytrain_file = os.path.join(save_path, 'Ytrain.csv')\n",
    "XTrain_df.to_csv(Xtrain_file, index=False)\n",
    "ytrain_df.to_csv(Ytrain_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
